{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the web scrapping i have use the INSTANT DATA SCAPER to scrap the web data into csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all require modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swapn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swapn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swapn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') #for word tokenization\n",
    "nltk.download('stopwords') #for removing or getting list of stopwords\n",
    "nltk.download('wordnet') #for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import  stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"google.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>feedback</th>\n",
       "      <th>review-snippet</th>\n",
       "      <th>review-full-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Komit Bagate</td>\n",
       "      <td>Positive:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>omkar thorat</td>\n",
       "      <td>Positive:</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apoorva Shelar</td>\n",
       "      <td>Positive:</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shailesh Jadhav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IT vedant is very excellent institution, Becau...</td>\n",
       "      <td>IT vedant is very excellent institution, Becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Siddhi Lale</td>\n",
       "      <td>Positive:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>HersheyOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Yogesh Bhurawane</td>\n",
       "      <td>Critical:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Sunil Bhave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>swapnil gondkar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>shelar vaibhav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Names   feedback  \\\n",
       "0        Komit Bagate  Positive:   \n",
       "1        omkar thorat  Positive:   \n",
       "2      Apoorva Shelar  Positive:   \n",
       "3     Shailesh Jadhav        NaN   \n",
       "4         Siddhi Lale  Positive:   \n",
       "..                ...        ...   \n",
       "281         HersheyOP        NaN   \n",
       "282  Yogesh Bhurawane  Critical:   \n",
       "283       Sunil Bhave        NaN   \n",
       "284   swapnil gondkar        NaN   \n",
       "285    shelar vaibhav        NaN   \n",
       "\n",
       "                                        review-snippet  \\\n",
       "0                                                  NaN   \n",
       "1    I enrolled for data science course. I got to l...   \n",
       "2    All the teaching staff and non-teaching staff ...   \n",
       "3    IT vedant is very excellent institution, Becau...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "281                                                NaN   \n",
       "282                                                NaN   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "\n",
       "                                      review-full-text  \n",
       "0                                                  NaN  \n",
       "1    I enrolled for data science course. I got to l...  \n",
       "2    All the teaching staff and non-teaching staff ...  \n",
       "3    IT vedant is very excellent institution, Becau...  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "281                                                NaN  \n",
       "282                                                NaN  \n",
       "283                                                NaN  \n",
       "284                                                NaN  \n",
       "285                                                NaN  \n",
       "\n",
       "[286 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"review-snippet\"],axis=1,inplace=True)\n",
    "df.drop([\"Names\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>review-full-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>IT vedant is very excellent institution, Becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Critical:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feedback                                   review-full-text\n",
       "0    Positive:                                                NaN\n",
       "1    Positive:  I enrolled for data science course. I got to l...\n",
       "2    Positive:  All the teaching staff and non-teaching staff ...\n",
       "3          NaN  IT vedant is very excellent institution, Becau...\n",
       "4    Positive:                                                NaN\n",
       "..         ...                                                ...\n",
       "281        NaN                                                NaN\n",
       "282  Critical:                                                NaN\n",
       "283        NaN                                                NaN\n",
       "284        NaN                                                NaN\n",
       "285        NaN                                                NaN\n",
       "\n",
       "[286 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feedback            186\n",
       "review-full-text    213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#measure the nan(null) values in df\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedback            65.034965\n",
      "review-full-text    74.475524\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#percentage of nan(null) values in df\n",
    "nullper=(df.isnull().sum()/len(df))*100\n",
    "print(nullper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0 ,inplace=True) #delete those rows who has NAN values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>review-full-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I was looking forward to enhancing my technica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined I.T. Vedant in march 2020 to learn Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I was looking forward to enhancing my technica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined I.T. Vedant in march 2020 to learn Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Itvedant is a great institute to look for, if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I have joined this institute on 3rd Sept. 2019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I just attended the counselling session and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I am currently enrolled in Data Science course...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I have enrolled for the Data science class in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined ITVedant in December 2020. I enrolled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I had completed Data science course from Itved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Joined Itvedant on August 2020 , So here's my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Itvedant have not only a student friendly envi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>ItVedant is a amazing institute for different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined IT Vedant for data science course.Tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>IT-Vedant is a very good Institute where you c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Hi, during lockdown I had so much of spare tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined Itvedant few months back to enroll my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Firstly I really want to appreciate and thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>IT Vedant is a good institute they actually he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Itvedant is the best place for learning variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Itvedant is best training institute for IT cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I would highly recommend ITVedant. The institu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Personal attention given by the faculty is why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Good  institude .specially namrata mam provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>One of the best institute for python , dbms , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I had enrolled for Data science basic course a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined ITVedant in December 2019. I enrolled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>\"Perfection &amp; excellence way of teaching\"\".SHI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>ITVedant gives me best in class career guidanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>(Translated by Google) Meena mam, chetna mam, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feedback                                   review-full-text\n",
       "1    Positive:  I enrolled for data science course. I got to l...\n",
       "2    Positive:  All the teaching staff and non-teaching staff ...\n",
       "6    Positive:  I was looking forward to enhancing my technica...\n",
       "7    Positive:  I joined I.T. Vedant in march 2020 to learn Py...\n",
       "11   Positive:  I enrolled for data science course. I got to l...\n",
       "12   Positive:  All the teaching staff and non-teaching staff ...\n",
       "16   Positive:  I was looking forward to enhancing my technica...\n",
       "17   Positive:  I joined I.T. Vedant in march 2020 to learn Py...\n",
       "20   Positive:  Itvedant is a great institute to look for, if ...\n",
       "21   Positive:  I have joined this institute on 3rd Sept. 2019...\n",
       "22   Positive:  I just attended the counselling session and it...\n",
       "23   Positive:  I am currently enrolled in Data Science course...\n",
       "26   Positive:  I have enrolled for the Data science class in ...\n",
       "28   Positive:  I joined ITVedant in December 2020. I enrolled...\n",
       "31   Positive:  I had completed Data science course from Itved...\n",
       "32   Positive:  Joined Itvedant on August 2020 , So here's my ...\n",
       "33   Positive:  Itvedant have not only a student friendly envi...\n",
       "34   Positive:  ItVedant is a amazing institute for different ...\n",
       "37   Positive:  I joined IT Vedant for data science course.Tea...\n",
       "38   Positive:  IT-Vedant is a very good Institute where you c...\n",
       "40   Positive:  Hi, during lockdown I had so much of spare tim...\n",
       "43   Positive:  I joined Itvedant few months back to enroll my...\n",
       "45   Positive:  Firstly I really want to appreciate and thank ...\n",
       "52   Positive:  IT Vedant is a good institute they actually he...\n",
       "53   Positive:  Itvedant is the best place for learning variou...\n",
       "54   Positive:  Itvedant is best training institute for IT cou...\n",
       "55   Positive:  I would highly recommend ITVedant. The institu...\n",
       "56   Positive:  Personal attention given by the faculty is why...\n",
       "64   Positive:  Good  institude .specially namrata mam provide...\n",
       "67   Positive:  One of the best institute for python , dbms , ...\n",
       "73   Positive:  I had enrolled for Data science basic course a...\n",
       "78   Positive:  I joined ITVedant in December 2019. I enrolled...\n",
       "85   Positive:  \"Perfection & excellence way of teaching\"\".SHI...\n",
       "88   Positive:  ITVedant gives me best in class career guidanc...\n",
       "207  Positive:  (Translated by Google) Meena mam, chetna mam, ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df                  #35 rows are non null it is not good for data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35 entries, 1 to 207\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   feedback          35 non-null     object\n",
      " 1   review-full-text  35 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 840.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info() #35 rows are non null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feedback            0\n",
       "review-full-text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value treatment in categorical values using mode \n",
    "#df['feedback'] = df['feedback'].fillna(df['feedback'].mode()[0])\n",
    "#df['review-full-text'] = df['review-full-text'].fillna(df['review-full-text'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>review-full-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I was looking forward to enhancing my technica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined I.T. Vedant in march 2020 to learn Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I was looking forward to enhancing my technica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined I.T. Vedant in march 2020 to learn Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Itvedant is a great institute to look for, if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I have joined this institute on 3rd Sept. 2019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I just attended the counselling session and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I am currently enrolled in Data Science course...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I have enrolled for the Data science class in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined ITVedant in December 2020. I enrolled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I had completed Data science course from Itved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Joined Itvedant on August 2020 , So here's my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Itvedant have not only a student friendly envi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>ItVedant is a amazing institute for different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined IT Vedant for data science course.Tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>IT-Vedant is a very good Institute where you c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Hi, during lockdown I had so much of spare tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined Itvedant few months back to enroll my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Firstly I really want to appreciate and thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>IT Vedant is a good institute they actually he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Itvedant is the best place for learning variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Itvedant is best training institute for IT cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I would highly recommend ITVedant. The institu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Personal attention given by the faculty is why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>Good  institude .specially namrata mam provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>One of the best institute for python , dbms , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I had enrolled for Data science basic course a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>I joined ITVedant in December 2019. I enrolled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>\"Perfection &amp; excellence way of teaching\"\".SHI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>ITVedant gives me best in class career guidanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Positive:</td>\n",
       "      <td>(Translated by Google) Meena mam, chetna mam, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feedback                                   review-full-text\n",
       "1    Positive:  I enrolled for data science course. I got to l...\n",
       "2    Positive:  All the teaching staff and non-teaching staff ...\n",
       "6    Positive:  I was looking forward to enhancing my technica...\n",
       "7    Positive:  I joined I.T. Vedant in march 2020 to learn Py...\n",
       "11   Positive:  I enrolled for data science course. I got to l...\n",
       "12   Positive:  All the teaching staff and non-teaching staff ...\n",
       "16   Positive:  I was looking forward to enhancing my technica...\n",
       "17   Positive:  I joined I.T. Vedant in march 2020 to learn Py...\n",
       "20   Positive:  Itvedant is a great institute to look for, if ...\n",
       "21   Positive:  I have joined this institute on 3rd Sept. 2019...\n",
       "22   Positive:  I just attended the counselling session and it...\n",
       "23   Positive:  I am currently enrolled in Data Science course...\n",
       "26   Positive:  I have enrolled for the Data science class in ...\n",
       "28   Positive:  I joined ITVedant in December 2020. I enrolled...\n",
       "31   Positive:  I had completed Data science course from Itved...\n",
       "32   Positive:  Joined Itvedant on August 2020 , So here's my ...\n",
       "33   Positive:  Itvedant have not only a student friendly envi...\n",
       "34   Positive:  ItVedant is a amazing institute for different ...\n",
       "37   Positive:  I joined IT Vedant for data science course.Tea...\n",
       "38   Positive:  IT-Vedant is a very good Institute where you c...\n",
       "40   Positive:  Hi, during lockdown I had so much of spare tim...\n",
       "43   Positive:  I joined Itvedant few months back to enroll my...\n",
       "45   Positive:  Firstly I really want to appreciate and thank ...\n",
       "52   Positive:  IT Vedant is a good institute they actually he...\n",
       "53   Positive:  Itvedant is the best place for learning variou...\n",
       "54   Positive:  Itvedant is best training institute for IT cou...\n",
       "55   Positive:  I would highly recommend ITVedant. The institu...\n",
       "56   Positive:  Personal attention given by the faculty is why...\n",
       "64   Positive:  Good  institude .specially namrata mam provide...\n",
       "67   Positive:  One of the best institute for python , dbms , ...\n",
       "73   Positive:  I had enrolled for Data science basic course a...\n",
       "78   Positive:  I joined ITVedant in December 2019. I enrolled...\n",
       "85   Positive:  \"Perfection & excellence way of teaching\"\".SHI...\n",
       "88   Positive:  ITVedant gives me best in class career guidanc...\n",
       "207  Positive:  (Translated by Google) Meena mam, chetna mam, ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "le=LabelEncoder()\n",
    "for col in df:\n",
    "    df['feedback']=le.fit_transform(df['feedback'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>review-full-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>I was looking forward to enhancing my technica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>I joined I.T. Vedant in march 2020 to learn Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>I enrolled for data science course. I got to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>All the teaching staff and non-teaching staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>I was looking forward to enhancing my technica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>I joined I.T. Vedant in march 2020 to learn Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Itvedant is a great institute to look for, if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>I have joined this institute on 3rd Sept. 2019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>I just attended the counselling session and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>I am currently enrolled in Data Science course...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>I have enrolled for the Data science class in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>I joined ITVedant in December 2020. I enrolled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>I had completed Data science course from Itved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>Joined Itvedant on August 2020 , So here's my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>Itvedant have not only a student friendly envi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>ItVedant is a amazing institute for different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>I joined IT Vedant for data science course.Tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>IT-Vedant is a very good Institute where you c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi, during lockdown I had so much of spare tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>I joined Itvedant few months back to enroll my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>Firstly I really want to appreciate and thank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>IT Vedant is a good institute they actually he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>Itvedant is the best place for learning variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>Itvedant is best training institute for IT cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>I would highly recommend ITVedant. The institu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>Personal attention given by the faculty is why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>Good  institude .specially namrata mam provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the best institute for python , dbms , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>I had enrolled for Data science basic course a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>I joined ITVedant in December 2019. I enrolled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Perfection &amp; excellence way of teaching\"\".SHI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>ITVedant gives me best in class career guidanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>(Translated by Google) Meena mam, chetna mam, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feedback                                   review-full-text\n",
       "1           0  I enrolled for data science course. I got to l...\n",
       "2           0  All the teaching staff and non-teaching staff ...\n",
       "6           0  I was looking forward to enhancing my technica...\n",
       "7           0  I joined I.T. Vedant in march 2020 to learn Py...\n",
       "11          0  I enrolled for data science course. I got to l...\n",
       "12          0  All the teaching staff and non-teaching staff ...\n",
       "16          0  I was looking forward to enhancing my technica...\n",
       "17          0  I joined I.T. Vedant in march 2020 to learn Py...\n",
       "20          0  Itvedant is a great institute to look for, if ...\n",
       "21          0  I have joined this institute on 3rd Sept. 2019...\n",
       "22          0  I just attended the counselling session and it...\n",
       "23          0  I am currently enrolled in Data Science course...\n",
       "26          0  I have enrolled for the Data science class in ...\n",
       "28          0  I joined ITVedant in December 2020. I enrolled...\n",
       "31          0  I had completed Data science course from Itved...\n",
       "32          0  Joined Itvedant on August 2020 , So here's my ...\n",
       "33          0  Itvedant have not only a student friendly envi...\n",
       "34          0  ItVedant is a amazing institute for different ...\n",
       "37          0  I joined IT Vedant for data science course.Tea...\n",
       "38          0  IT-Vedant is a very good Institute where you c...\n",
       "40          0  Hi, during lockdown I had so much of spare tim...\n",
       "43          0  I joined Itvedant few months back to enroll my...\n",
       "45          0  Firstly I really want to appreciate and thank ...\n",
       "52          0  IT Vedant is a good institute they actually he...\n",
       "53          0  Itvedant is the best place for learning variou...\n",
       "54          0  Itvedant is best training institute for IT cou...\n",
       "55          0  I would highly recommend ITVedant. The institu...\n",
       "56          0  Personal attention given by the faculty is why...\n",
       "64          0  Good  institude .specially namrata mam provide...\n",
       "67          0  One of the best institute for python , dbms , ...\n",
       "73          0  I had enrolled for Data science basic course a...\n",
       "78          0  I joined ITVedant in December 2019. I enrolled...\n",
       "85          0  \"Perfection & excellence way of teaching\"\".SHI...\n",
       "88          0  ITVedant gives me best in class career guidanc...\n",
       "207         0  (Translated by Google) Meena mam, chetna mam, ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")\n",
    "def clean_text(text):\n",
    "  tokens = word_tokenize(text.lower())\n",
    "  # Filter only alphabets\n",
    "  word_tokens = [t for t in tokens if t.isalpha()]\n",
    "  clean_tokens = [t for t in word_tokens if t not in stop]\n",
    "  lemma = WordNetLemmatizer()\n",
    "  lemma_tokens = [lemma.lemmatize(t) for t in clean_tokens]\n",
    "  return \" \".join(lemma_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review-full-text'] = df['review-full-text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     enrolled data science course got learn many th...\n",
       "2     teaching staff staff professional available as...\n",
       "6     looking forward enhancing technical knowledge ...\n",
       "7     joined vedant march learn python language hone...\n",
       "11    enrolled data science course got learn many th...\n",
       "Name: review-full-text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review-full-text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df['review-full-text']\n",
    "y= df['feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>review-full-text</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>enrolled data science course got learn many th...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>teaching staff staff professional available as...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>looking forward enhancing technical knowledge ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>joined vedant march learn python language hone...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>enrolled data science course got learn many th...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feedback                                   review-full-text  sent_len\n",
       "1          0  enrolled data science course got learn many th...        39\n",
       "2          0  teaching staff staff professional available as...        32\n",
       "6          0  looking forward enhancing technical knowledge ...        31\n",
       "7          0  joined vedant march learn python language hone...        80\n",
       "11         0  enrolled data science course got learn many th...        39"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len = []\n",
    "for t in df['review-full-text']:\n",
    "  sent_len.append(len(word_tokenize(t)))\n",
    "df['sent_len'] = sent_len\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(sent_len, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "# Creates dictionary and every unique word is given number key\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# To perform the padding of the documents with zero's to make the length of the\n",
    "# document common\n",
    "from tensorflow.keras.layers import (LSTM, Dropout, Embedding, SimpleRNN, GRU)\n",
    "# All the index numbers are converted to vectors using Embedding\n",
    "# SimpleRNN allows to implement the RNN architecture - activation function -tanh\n",
    "# Dropout - manage overfitting of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tok = Tokenizer(char_level=False, split=\" \")\n",
    "tok.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'itvedant',\n",
       " 2: 'knowledge',\n",
       " 3: 'also',\n",
       " 4: 'course',\n",
       " 5: 'staff',\n",
       " 6: 'teaching',\n",
       " 7: 'institute',\n",
       " 8: 'learning',\n",
       " 9: 'good',\n",
       " 10: 'best',\n",
       " 11: 'experience',\n",
       " 12: 'data',\n",
       " 13: 'science',\n",
       " 14: 'practical',\n",
       " 15: 'would',\n",
       " 16: 'help',\n",
       " 17: 'sir',\n",
       " 18: 'concept',\n",
       " 19: 'topic',\n",
       " 20: 'faculty',\n",
       " 21: 'enrolled',\n",
       " 22: 'python',\n",
       " 23: 'joined',\n",
       " 24: 'vedant',\n",
       " 25: 'recommend',\n",
       " 26: 'get',\n",
       " 27: 'really',\n",
       " 28: 'great',\n",
       " 29: 'supportive',\n",
       " 30: 'mam',\n",
       " 31: 'like',\n",
       " 32: 'thing',\n",
       " 33: 'got',\n",
       " 34: 'helpful',\n",
       " 35: 'every',\n",
       " 36: 'student',\n",
       " 37: 'assignment',\n",
       " 38: 'doubt',\n",
       " 39: 'understand',\n",
       " 40: 'friendly',\n",
       " 41: 'class',\n",
       " 42: 'session',\n",
       " 43: 'way',\n",
       " 44: 'much',\n",
       " 45: 'development',\n",
       " 46: 'want',\n",
       " 47: 'learn',\n",
       " 48: 'project',\n",
       " 49: 'excellent',\n",
       " 50: 'meena',\n",
       " 51: 'always',\n",
       " 52: 'understanding',\n",
       " 53: 'theoretical',\n",
       " 54: 'given',\n",
       " 55: 'solving',\n",
       " 56: 'experienced',\n",
       " 57: 'programming',\n",
       " 58: 'everyone',\n",
       " 59: 'field',\n",
       " 60: 'clear',\n",
       " 61: 'far',\n",
       " 62: 'highly',\n",
       " 63: 'non',\n",
       " 64: 'work',\n",
       " 65: 'training',\n",
       " 66: 'many',\n",
       " 67: 'technical',\n",
       " 68: 'especially',\n",
       " 69: 'solve',\n",
       " 70: 'interesting',\n",
       " 71: 'gain',\n",
       " 72: 'mentor',\n",
       " 73: 'helped',\n",
       " 74: 'shirish',\n",
       " 75: 'zafar',\n",
       " 76: 'web',\n",
       " 77: 'skill',\n",
       " 78: 'fun',\n",
       " 79: 'time',\n",
       " 80: 'place',\n",
       " 81: 'month',\n",
       " 82: 'thank',\n",
       " 83: 'language',\n",
       " 84: 'part',\n",
       " 85: 'placed',\n",
       " 86: 'basic',\n",
       " 87: 'better',\n",
       " 88: 'looking',\n",
       " 89: 'enhancing',\n",
       " 90: 'well',\n",
       " 91: 'overall',\n",
       " 92: 'available',\n",
       " 93: 'namrata',\n",
       " 94: 'teach',\n",
       " 95: 'machine',\n",
       " 96: 'knowledgeable',\n",
       " 97: 'ready',\n",
       " 98: 'provide',\n",
       " 99: 'material',\n",
       " 100: 'note',\n",
       " 101: 'team',\n",
       " 102: 'actually',\n",
       " 103: 'helping',\n",
       " 104: 'gon',\n",
       " 105: 'na',\n",
       " 106: 'ml',\n",
       " 107: 'currently',\n",
       " 108: 'insight',\n",
       " 109: 'providing',\n",
       " 110: 'test',\n",
       " 111: 'people',\n",
       " 112: 'grow',\n",
       " 113: 'future',\n",
       " 114: 'etc',\n",
       " 115: 'professional',\n",
       " 116: 'lot',\n",
       " 117: 'join',\n",
       " 118: 'new',\n",
       " 119: 'full',\n",
       " 120: 'stack',\n",
       " 121: 'confident',\n",
       " 122: 'right',\n",
       " 123: 'everything',\n",
       " 124: 'could',\n",
       " 125: 'career',\n",
       " 126: 'honestly',\n",
       " 127: 'day',\n",
       " 128: 'sneha',\n",
       " 129: 'even',\n",
       " 130: 'completing',\n",
       " 131: 'case',\n",
       " 132: 'suggest',\n",
       " 133: 'grateful',\n",
       " 134: 'online',\n",
       " 135: 'enough',\n",
       " 136: 'computer',\n",
       " 137: 'provided',\n",
       " 138: 'facility',\n",
       " 139: 'definitely',\n",
       " 140: 'forward',\n",
       " 141: 'ago',\n",
       " 142: 'told',\n",
       " 143: 'technology',\n",
       " 144: 'example',\n",
       " 145: 'make',\n",
       " 146: 'required',\n",
       " 147: 'look',\n",
       " 148: 'maam',\n",
       " 149: 'strong',\n",
       " 150: 'background',\n",
       " 151: 'various',\n",
       " 152: 'enquiry',\n",
       " 153: 'preeti',\n",
       " 154: 'management',\n",
       " 155: 'industry',\n",
       " 156: 'learnedmany',\n",
       " 157: 'terminology',\n",
       " 158: 'proactive',\n",
       " 159: 'pandey',\n",
       " 160: 'yo',\n",
       " 161: 'query',\n",
       " 162: 'rajani',\n",
       " 163: 'related',\n",
       " 164: 'practice',\n",
       " 165: 'attended',\n",
       " 166: 'counselling',\n",
       " 167: 'par',\n",
       " 168: 'head',\n",
       " 169: 'counsellor',\n",
       " 170: 'miss',\n",
       " 171: 'pooja',\n",
       " 172: 'salgaonkar',\n",
       " 173: 'mindset',\n",
       " 174: 'fresher',\n",
       " 175: 'andd',\n",
       " 176: 'tried',\n",
       " 177: 'walk',\n",
       " 178: 'shoe',\n",
       " 179: 'find',\n",
       " 180: 'effectiveness',\n",
       " 181: 'towards',\n",
       " 182: 'honest',\n",
       " 183: 'hype',\n",
       " 184: 'anything',\n",
       " 185: 'transparent',\n",
       " 186: 'bring',\n",
       " 187: 'table',\n",
       " 188: 'raise',\n",
       " 189: 'cv',\n",
       " 190: 'edge',\n",
       " 191: 'others',\n",
       " 192: 'delighted',\n",
       " 193: 'come',\n",
       " 194: 'across',\n",
       " 195: 'guiding',\n",
       " 196: 'trust',\n",
       " 197: 'rely',\n",
       " 198: 'upon',\n",
       " 199: 'one',\n",
       " 200: 'dbms',\n",
       " 201: 'sirish',\n",
       " 202: 'stage',\n",
       " 203: 'gaining',\n",
       " 204: 'useful',\n",
       " 205: 'application',\n",
       " 206: 'difficulty',\n",
       " 207: 'problem',\n",
       " 208: 'cemented',\n",
       " 209: 'aspiring',\n",
       " 210: 'try',\n",
       " 211: 'individually',\n",
       " 212: 'stand',\n",
       " 213: 'december',\n",
       " 214: 'database',\n",
       " 215: 'django',\n",
       " 216: 'must',\n",
       " 217: 'say',\n",
       " 218: 'nice',\n",
       " 219: 'trainer',\n",
       " 220: 'mayuresh',\n",
       " 221: 'pranit',\n",
       " 222: 'learnt',\n",
       " 223: 'evolved',\n",
       " 224: 'august',\n",
       " 225: 'journey',\n",
       " 226: 'started',\n",
       " 227: 'developer',\n",
       " 228: 'practically',\n",
       " 229: 'hand',\n",
       " 230: 'theory',\n",
       " 231: 'humbled',\n",
       " 232: 'polite',\n",
       " 233: 'nature',\n",
       " 234: 'going',\n",
       " 235: 'guide',\n",
       " 236: 'single',\n",
       " 237: 'step',\n",
       " 238: 'input',\n",
       " 239: 'taking',\n",
       " 240: 'valuable',\n",
       " 241: 'indeed',\n",
       " 242: 'strategy',\n",
       " 243: 'awesome',\n",
       " 244: 'eventhough',\n",
       " 245: 'task',\n",
       " 246: 'period',\n",
       " 247: 'upgrade',\n",
       " 248: 'software',\n",
       " 249: 'back',\n",
       " 250: 'enroll',\n",
       " 251: 'learned',\n",
       " 252: 'specially',\n",
       " 253: 'amreen',\n",
       " 254: 'glad',\n",
       " 255: 'newbie',\n",
       " 256: 'anyone',\n",
       " 257: 'pursue',\n",
       " 258: 'march',\n",
       " 259: 'clue',\n",
       " 260: 'cause',\n",
       " 261: 'school',\n",
       " 262: 'lohana',\n",
       " 263: 'amazing',\n",
       " 264: 'super',\n",
       " 265: 'touch',\n",
       " 266: 'took',\n",
       " 267: 'little',\n",
       " 268: 'idea',\n",
       " 269: 'patient',\n",
       " 270: 'repeated',\n",
       " 271: 'grab',\n",
       " 272: 'first',\n",
       " 273: 'rather',\n",
       " 274: 'spending',\n",
       " 275: 'huge',\n",
       " 276: 'sum',\n",
       " 277: 'money',\n",
       " 278: 'company',\n",
       " 279: 'edureka',\n",
       " 280: 'coursera',\n",
       " 281: 'swear',\n",
       " 282: 'torry',\n",
       " 283: 'harris',\n",
       " 284: 'business',\n",
       " 285: 'solution',\n",
       " 286: 'hope',\n",
       " 287: 'recognition',\n",
       " 288: 'deserves',\n",
       " 289: 'firstly',\n",
       " 290: 'appreciate',\n",
       " 291: 'platform',\n",
       " 292: 'belong',\n",
       " 293: 'rural',\n",
       " 294: 'area',\n",
       " 295: 'rajasthan',\n",
       " 296: 'thus',\n",
       " 297: 'complete',\n",
       " 298: 'attentive',\n",
       " 299: 'special',\n",
       " 300: 'thanks',\n",
       " 301: 'archana',\n",
       " 302: 'analyzed',\n",
       " 303: 'ability',\n",
       " 304: 'weakness',\n",
       " 305: 'strengthen',\n",
       " 306: 'weak',\n",
       " 307: 'point',\n",
       " 308: 'interactive',\n",
       " 309: 'attention',\n",
       " 310: 'approach',\n",
       " 311: 'study',\n",
       " 312: 'intro',\n",
       " 313: 'resume',\n",
       " 314: 'preparation',\n",
       " 315: 'cracking',\n",
       " 316: 'enthusiast',\n",
       " 317: 'willing',\n",
       " 318: 'recommended',\n",
       " 319: 'assistance',\n",
       " 320: 'pg',\n",
       " 321: 'arrangement',\n",
       " 322: 'upto',\n",
       " 323: 'date',\n",
       " 324: 'portal',\n",
       " 325: 'app',\n",
       " 326: 'keep',\n",
       " 327: 'track',\n",
       " 328: 'progress',\n",
       " 329: 'encourage',\n",
       " 330: 'followed',\n",
       " 331: 'path',\n",
       " 332: 'n',\n",
       " 333: 'interview',\n",
       " 334: 'thane',\n",
       " 335: 'job',\n",
       " 336: 'biggest',\n",
       " 337: 'benefit',\n",
       " 338: 'joining',\n",
       " 339: 'mumbai',\n",
       " 340: 'provides',\n",
       " 341: 'placement',\n",
       " 342: 'guarantee',\n",
       " 343: 'agreement',\n",
       " 344: 'recently',\n",
       " 345: 'youth',\n",
       " 346: 'brief',\n",
       " 347: 'infrastructure',\n",
       " 348: 'affordable',\n",
       " 349: 'fee',\n",
       " 350: 'perfection',\n",
       " 351: 'excellence',\n",
       " 352: 'depth',\n",
       " 353: 'php',\n",
       " 354: 'alsoother',\n",
       " 355: 'elaborate',\n",
       " 356: 'simple',\n",
       " 357: 'mannerso',\n",
       " 358: 'institude',\n",
       " 359: 'kindsupport',\n",
       " 360: 'include',\n",
       " 361: 'andpractical',\n",
       " 362: 'quickly',\n",
       " 363: 'thxs',\n",
       " 364: 'pande',\n",
       " 365: 'guider',\n",
       " 366: 'andstudent',\n",
       " 367: 'environment',\n",
       " 368: 'share',\n",
       " 369: 'lockdown',\n",
       " 370: 'webinars',\n",
       " 371: 'organised',\n",
       " 372: 'show',\n",
       " 373: 'contribute',\n",
       " 374: 'starting',\n",
       " 375: 'panday',\n",
       " 376: 'explained',\n",
       " 377: 'simpliest',\n",
       " 378: 'humble',\n",
       " 379: 'made',\n",
       " 380: 'easier',\n",
       " 381: 'coding',\n",
       " 382: 'extremely',\n",
       " 383: 'method',\n",
       " 384: 'two',\n",
       " 385: 'communication',\n",
       " 386: 'focus',\n",
       " 387: 'clearing',\n",
       " 388: 'end',\n",
       " 389: 'surely',\n",
       " 390: 'give',\n",
       " 391: 'confidence',\n",
       " 392: 'develop',\n",
       " 393: 'module',\n",
       " 394: 'decode',\n",
       " 395: 'dream',\n",
       " 396: 'precise',\n",
       " 397: 'manner',\n",
       " 398: 'need',\n",
       " 399: 'code',\n",
       " 400: 'program',\n",
       " 401: 'sweet',\n",
       " 402: 'among',\n",
       " 403: 'unique',\n",
       " 404: 'style',\n",
       " 405: 'explains',\n",
       " 406: 'us',\n",
       " 407: 'hard',\n",
       " 408: 'easy',\n",
       " 409: 'explain',\n",
       " 410: 'till',\n",
       " 411: 'crystal',\n",
       " 412: 'top',\n",
       " 413: 'knowlegde',\n",
       " 414: 'covered',\n",
       " 415: 'taught',\n",
       " 416: 'lecture',\n",
       " 417: 'uninterrupted',\n",
       " 418: 'difference',\n",
       " 419: 'living',\n",
       " 420: 'uk',\n",
       " 421: 'support',\n",
       " 422: 'offered',\n",
       " 423: 'fantastic',\n",
       " 424: 'consistent',\n",
       " 425: 'thankful',\n",
       " 426: 'designed',\n",
       " 427: 'meet',\n",
       " 428: 'standard',\n",
       " 429: 'cover',\n",
       " 430: 'emphasis',\n",
       " 431: 'completed',\n",
       " 432: 'kindness',\n",
       " 433: 'shared',\n",
       " 434: 'impossible',\n",
       " 435: 'without',\n",
       " 436: 'guidence',\n",
       " 437: 'achieve',\n",
       " 438: 'goal',\n",
       " 439: 'thanking',\n",
       " 440: 'secure',\n",
       " 441: 'behaviour',\n",
       " 442: 'throughout'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(tok.index_word)\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[21,\n",
       "  12,\n",
       "  13,\n",
       "  41,\n",
       "  24,\n",
       "  156,\n",
       "  66,\n",
       "  67,\n",
       "  157,\n",
       "  22,\n",
       "  95,\n",
       "  8,\n",
       "  3,\n",
       "  6,\n",
       "  5,\n",
       "  158,\n",
       "  68,\n",
       "  50,\n",
       "  159,\n",
       "  30,\n",
       "  96,\n",
       "  51,\n",
       "  97,\n",
       "  160,\n",
       "  69,\n",
       "  161,\n",
       "  162,\n",
       "  30,\n",
       "  52,\n",
       "  51,\n",
       "  16,\n",
       "  41,\n",
       "  163,\n",
       "  53,\n",
       "  2,\n",
       "  3,\n",
       "  14,\n",
       "  2,\n",
       "  54,\n",
       "  41,\n",
       "  3,\n",
       "  98,\n",
       "  164,\n",
       "  99,\n",
       "  100,\n",
       "  101],\n",
       " [165,\n",
       "  166,\n",
       "  42,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  172,\n",
       "  43,\n",
       "  9,\n",
       "  52,\n",
       "  173,\n",
       "  174,\n",
       "  31,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  102,\n",
       "  103,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  8,\n",
       "  182,\n",
       "  70,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  32,\n",
       "  33,\n",
       "  186,\n",
       "  187,\n",
       "  32,\n",
       "  104,\n",
       "  105,\n",
       "  188,\n",
       "  189,\n",
       "  71,\n",
       "  190,\n",
       "  191,\n",
       "  44,\n",
       "  192,\n",
       "  193,\n",
       "  194,\n",
       "  195,\n",
       "  72,\n",
       "  196,\n",
       "  197,\n",
       "  198],\n",
       " [199, 10, 7, 22, 200, 106, 201, 17, 10, 5, 5, 34, 35, 202],\n",
       " [107,\n",
       "  21,\n",
       "  12,\n",
       "  13,\n",
       "  4,\n",
       "  1,\n",
       "  73,\n",
       "  203,\n",
       "  204,\n",
       "  108,\n",
       "  2,\n",
       "  205,\n",
       "  51,\n",
       "  16,\n",
       "  36,\n",
       "  206,\n",
       "  207,\n",
       "  208,\n",
       "  109,\n",
       "  9,\n",
       "  4,\n",
       "  99,\n",
       "  110,\n",
       "  37,\n",
       "  38,\n",
       "  55,\n",
       "  15,\n",
       "  25,\n",
       "  209,\n",
       "  111,\n",
       "  210,\n",
       "  4,\n",
       "  54,\n",
       "  1,\n",
       "  16,\n",
       "  112,\n",
       "  211,\n",
       "  3,\n",
       "  16,\n",
       "  39,\n",
       "  212,\n",
       "  113],\n",
       " [23,\n",
       "  1,\n",
       "  213,\n",
       "  21,\n",
       "  4,\n",
       "  22,\n",
       "  214,\n",
       "  215,\n",
       "  114,\n",
       "  216,\n",
       "  217,\n",
       "  8,\n",
       "  11,\n",
       "  1,\n",
       "  218,\n",
       "  219,\n",
       "  56,\n",
       "  115,\n",
       "  74,\n",
       "  17,\n",
       "  220,\n",
       "  17,\n",
       "  75,\n",
       "  17,\n",
       "  221,\n",
       "  17,\n",
       "  114,\n",
       "  222,\n",
       "  116,\n",
       "  32,\n",
       "  18,\n",
       "  76,\n",
       "  45,\n",
       "  1,\n",
       "  223,\n",
       "  57,\n",
       "  15,\n",
       "  25,\n",
       "  58,\n",
       "  117,\n",
       "  1,\n",
       "  46,\n",
       "  47,\n",
       "  57,\n",
       "  118,\n",
       "  77,\n",
       "  59],\n",
       " [23,\n",
       "  1,\n",
       "  224,\n",
       "  225,\n",
       "  226,\n",
       "  21,\n",
       "  119,\n",
       "  120,\n",
       "  76,\n",
       "  227,\n",
       "  26,\n",
       "  228,\n",
       "  229,\n",
       "  230,\n",
       "  26,\n",
       "  60,\n",
       "  52,\n",
       "  19,\n",
       "  5,\n",
       "  27,\n",
       "  231,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235,\n",
       "  35,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  42,\n",
       "  27,\n",
       "  240,\n",
       "  241,\n",
       "  8,\n",
       "  242,\n",
       "  243,\n",
       "  78,\n",
       "  244,\n",
       "  26,\n",
       "  37,\n",
       "  48,\n",
       "  26,\n",
       "  121,\n",
       "  245,\n",
       "  54,\n",
       "  79,\n",
       "  246,\n",
       "  11,\n",
       "  27,\n",
       "  46,\n",
       "  247,\n",
       "  59,\n",
       "  248,\n",
       "  122,\n",
       "  80],\n",
       " [23,\n",
       "  1,\n",
       "  81,\n",
       "  249,\n",
       "  250,\n",
       "  22,\n",
       "  45,\n",
       "  4,\n",
       "  251,\n",
       "  44,\n",
       "  61,\n",
       "  10,\n",
       "  6,\n",
       "  5,\n",
       "  15,\n",
       "  252,\n",
       "  31,\n",
       "  82,\n",
       "  253,\n",
       "  73,\n",
       "  44,\n",
       "  123,\n",
       "  27,\n",
       "  254,\n",
       "  124,\n",
       "  112,\n",
       "  77,\n",
       "  255,\n",
       "  62,\n",
       "  25,\n",
       "  1,\n",
       "  256,\n",
       "  46,\n",
       "  257,\n",
       "  125],\n",
       " [23,\n",
       "  24,\n",
       "  258,\n",
       "  47,\n",
       "  22,\n",
       "  83,\n",
       "  126,\n",
       "  259,\n",
       "  57,\n",
       "  260,\n",
       "  9,\n",
       "  261,\n",
       "  127,\n",
       "  20,\n",
       "  128,\n",
       "  262,\n",
       "  263,\n",
       "  27,\n",
       "  9,\n",
       "  10,\n",
       "  84,\n",
       "  8,\n",
       "  264,\n",
       "  78,\n",
       "  26,\n",
       "  265,\n",
       "  20,\n",
       "  129,\n",
       "  41,\n",
       "  60,\n",
       "  130,\n",
       "  22,\n",
       "  266,\n",
       "  95,\n",
       "  8,\n",
       "  126,\n",
       "  267,\n",
       "  268,\n",
       "  106,\n",
       "  128,\n",
       "  269,\n",
       "  58,\n",
       "  270,\n",
       "  19,\n",
       "  131,\n",
       "  271,\n",
       "  272,\n",
       "  15,\n",
       "  132,\n",
       "  58,\n",
       "  273,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  31,\n",
       "  279,\n",
       "  280,\n",
       "  117,\n",
       "  24,\n",
       "  281,\n",
       "  104,\n",
       "  105,\n",
       "  44,\n",
       "  78,\n",
       "  24,\n",
       "  33,\n",
       "  85,\n",
       "  282,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  51,\n",
       "  133,\n",
       "  286,\n",
       "  24,\n",
       "  26,\n",
       "  287,\n",
       "  288],\n",
       " [289,\n",
       "  27,\n",
       "  46,\n",
       "  290,\n",
       "  82,\n",
       "  1,\n",
       "  109,\n",
       "  49,\n",
       "  134,\n",
       "  291,\n",
       "  47,\n",
       "  71,\n",
       "  135,\n",
       "  2,\n",
       "  292,\n",
       "  293,\n",
       "  294,\n",
       "  295,\n",
       "  296,\n",
       "  86,\n",
       "  2,\n",
       "  57,\n",
       "  136,\n",
       "  13,\n",
       "  297,\n",
       "  119,\n",
       "  120,\n",
       "  76,\n",
       "  45,\n",
       "  27,\n",
       "  28,\n",
       "  135,\n",
       "  2,\n",
       "  11,\n",
       "  59,\n",
       "  63,\n",
       "  6,\n",
       "  5,\n",
       "  3,\n",
       "  29,\n",
       "  298,\n",
       "  103,\n",
       "  299,\n",
       "  300,\n",
       "  301,\n",
       "  75,\n",
       "  17,\n",
       "  302,\n",
       "  303,\n",
       "  304,\n",
       "  305,\n",
       "  306,\n",
       "  307,\n",
       "  73,\n",
       "  39,\n",
       "  86,\n",
       "  32,\n",
       "  64,\n",
       "  137,\n",
       "  10,\n",
       "  138,\n",
       "  31,\n",
       "  308,\n",
       "  309,\n",
       "  35,\n",
       "  38,\n",
       "  42,\n",
       "  100,\n",
       "  37,\n",
       "  26,\n",
       "  14,\n",
       "  310,\n",
       "  131,\n",
       "  311,\n",
       "  87,\n",
       "  108,\n",
       "  53,\n",
       "  14,\n",
       "  312,\n",
       "  110,\n",
       "  77,\n",
       "  313,\n",
       "  314,\n",
       "  42,\n",
       "  315,\n",
       "  66,\n",
       "  15,\n",
       "  139,\n",
       "  132,\n",
       "  316,\n",
       "  317,\n",
       "  71,\n",
       "  2,\n",
       "  59,\n",
       "  62,\n",
       "  318],\n",
       " [88,\n",
       "  140,\n",
       "  89,\n",
       "  67,\n",
       "  2,\n",
       "  61,\n",
       "  23,\n",
       "  1,\n",
       "  7,\n",
       "  81,\n",
       "  141,\n",
       "  21,\n",
       "  22,\n",
       "  45,\n",
       "  6,\n",
       "  5,\n",
       "  29,\n",
       "  3,\n",
       "  20,\n",
       "  34,\n",
       "  38,\n",
       "  55,\n",
       "  90,\n",
       "  56,\n",
       "  14,\n",
       "  64,\n",
       "  37,\n",
       "  48,\n",
       "  91,\n",
       "  28,\n",
       "  11],\n",
       " [6,\n",
       "  5,\n",
       "  5,\n",
       "  115,\n",
       "  92,\n",
       "  319,\n",
       "  12,\n",
       "  13,\n",
       "  320,\n",
       "  4,\n",
       "  7,\n",
       "  11,\n",
       "  321,\n",
       "  322,\n",
       "  323,\n",
       "  3,\n",
       "  324,\n",
       "  325,\n",
       "  16,\n",
       "  101,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  329,\n",
       "  123,\n",
       "  142,\n",
       "  330,\n",
       "  331,\n",
       "  332,\n",
       "  33,\n",
       "  85,\n",
       "  333],\n",
       " [21,\n",
       "  12,\n",
       "  13,\n",
       "  86,\n",
       "  4,\n",
       "  1,\n",
       "  334,\n",
       "  15,\n",
       "  25,\n",
       "  58,\n",
       "  107,\n",
       "  88,\n",
       "  335,\n",
       "  12,\n",
       "  13,\n",
       "  4,\n",
       "  336,\n",
       "  337,\n",
       "  338,\n",
       "  7,\n",
       "  339,\n",
       "  340,\n",
       "  341,\n",
       "  342,\n",
       "  343,\n",
       "  344,\n",
       "  85,\n",
       "  345,\n",
       "  143,\n",
       "  346,\n",
       "  49,\n",
       "  5,\n",
       "  9,\n",
       "  347,\n",
       "  348,\n",
       "  349,\n",
       "  82,\n",
       "  1],\n",
       " [350,\n",
       "  351,\n",
       "  43,\n",
       "  6,\n",
       "  17,\n",
       "  10,\n",
       "  144,\n",
       "  352,\n",
       "  2,\n",
       "  138,\n",
       "  49,\n",
       "  47,\n",
       "  116,\n",
       "  118,\n",
       "  2,\n",
       "  353,\n",
       "  354,\n",
       "  74,\n",
       "  355,\n",
       "  35,\n",
       "  19,\n",
       "  356,\n",
       "  357,\n",
       "  39,\n",
       "  18,\n",
       "  49,\n",
       "  65,\n",
       "  54,\n",
       "  1],\n",
       " [9,\n",
       "  358,\n",
       "  93,\n",
       "  30,\n",
       "  98,\n",
       "  359,\n",
       "  145,\n",
       "  121,\n",
       "  65,\n",
       "  42,\n",
       "  3,\n",
       "  9,\n",
       "  360,\n",
       "  53,\n",
       "  361,\n",
       "  65,\n",
       "  16,\n",
       "  39,\n",
       "  32,\n",
       "  362,\n",
       "  3,\n",
       "  31,\n",
       "  363,\n",
       "  50,\n",
       "  364,\n",
       "  30,\n",
       "  9,\n",
       "  365,\n",
       "  366,\n",
       "  40],\n",
       " [1,\n",
       "  36,\n",
       "  40,\n",
       "  367,\n",
       "  8,\n",
       "  18,\n",
       "  12,\n",
       "  13,\n",
       "  4,\n",
       "  3,\n",
       "  20,\n",
       "  368,\n",
       "  11,\n",
       "  146,\n",
       "  16,\n",
       "  36,\n",
       "  147,\n",
       "  68,\n",
       "  369,\n",
       "  134,\n",
       "  41,\n",
       "  370,\n",
       "  371,\n",
       "  372,\n",
       "  44,\n",
       "  1,\n",
       "  373,\n",
       "  113,\n",
       "  35,\n",
       "  36,\n",
       "  10,\n",
       "  80,\n",
       "  125,\n",
       "  374,\n",
       "  89,\n",
       "  2,\n",
       "  15,\n",
       "  62,\n",
       "  25,\n",
       "  1,\n",
       "  12],\n",
       " [23,\n",
       "  24,\n",
       "  12,\n",
       "  13,\n",
       "  63,\n",
       "  6,\n",
       "  5,\n",
       "  50,\n",
       "  375,\n",
       "  148,\n",
       "  28,\n",
       "  8,\n",
       "  11,\n",
       "  18,\n",
       "  376,\n",
       "  377,\n",
       "  93,\n",
       "  148,\n",
       "  378,\n",
       "  6,\n",
       "  63,\n",
       "  6,\n",
       "  5,\n",
       "  40,\n",
       "  69,\n",
       "  38,\n",
       "  14,\n",
       "  2,\n",
       "  379,\n",
       "  380,\n",
       "  39,\n",
       "  18,\n",
       "  90],\n",
       " [88,\n",
       "  140,\n",
       "  89,\n",
       "  67,\n",
       "  2,\n",
       "  61,\n",
       "  23,\n",
       "  1,\n",
       "  7,\n",
       "  81,\n",
       "  141,\n",
       "  21,\n",
       "  22,\n",
       "  45,\n",
       "  6,\n",
       "  5,\n",
       "  29,\n",
       "  3,\n",
       "  20,\n",
       "  34,\n",
       "  38,\n",
       "  55,\n",
       "  90,\n",
       "  56,\n",
       "  14,\n",
       "  64,\n",
       "  37,\n",
       "  48,\n",
       "  91,\n",
       "  28,\n",
       "  11],\n",
       " [1,\n",
       "  28,\n",
       "  7,\n",
       "  147,\n",
       "  46,\n",
       "  381,\n",
       "  18,\n",
       "  149,\n",
       "  60,\n",
       "  20,\n",
       "  382,\n",
       "  29,\n",
       "  383,\n",
       "  6,\n",
       "  28,\n",
       "  384,\n",
       "  43,\n",
       "  385,\n",
       "  10,\n",
       "  84,\n",
       "  386,\n",
       "  14,\n",
       "  2,\n",
       "  16,\n",
       "  387,\n",
       "  18,\n",
       "  388,\n",
       "  389,\n",
       "  390,\n",
       "  391,\n",
       "  392,\n",
       "  48,\n",
       "  393],\n",
       " [24,\n",
       "  9,\n",
       "  7,\n",
       "  102,\n",
       "  16,\n",
       "  394,\n",
       "  395,\n",
       "  20,\n",
       "  56,\n",
       "  94,\n",
       "  35,\n",
       "  18,\n",
       "  396,\n",
       "  397,\n",
       "  398,\n",
       "  150,\n",
       "  150,\n",
       "  399,\n",
       "  400,\n",
       "  94,\n",
       "  43,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  401,\n",
       "  15,\n",
       "  139,\n",
       "  25],\n",
       " [1,\n",
       "  10,\n",
       "  80,\n",
       "  8,\n",
       "  151,\n",
       "  136,\n",
       "  83,\n",
       "  151,\n",
       "  143,\n",
       "  33,\n",
       "  9,\n",
       "  11,\n",
       "  122,\n",
       "  127,\n",
       "  152,\n",
       "  79,\n",
       "  152,\n",
       "  153,\n",
       "  142,\n",
       "  4,\n",
       "  10,\n",
       "  402,\n",
       "  92,\n",
       "  4,\n",
       "  7,\n",
       "  20,\n",
       "  403,\n",
       "  6,\n",
       "  404,\n",
       "  31,\n",
       "  75,\n",
       "  17,\n",
       "  50,\n",
       "  405,\n",
       "  19,\n",
       "  40,\n",
       "  83,\n",
       "  74,\n",
       "  17,\n",
       "  406,\n",
       "  144,\n",
       "  94,\n",
       "  19,\n",
       "  145,\n",
       "  407,\n",
       "  19,\n",
       "  408,\n",
       "  39,\n",
       "  111,\n",
       "  97,\n",
       "  409,\n",
       "  19,\n",
       "  410,\n",
       "  19,\n",
       "  411,\n",
       "  60,\n",
       "  14,\n",
       "  43,\n",
       "  6,\n",
       "  10,\n",
       "  84,\n",
       "  92,\n",
       "  36,\n",
       "  412,\n",
       "  154,\n",
       "  34,\n",
       "  29],\n",
       " [23,\n",
       "  7,\n",
       "  28,\n",
       "  11,\n",
       "  7,\n",
       "  8,\n",
       "  33,\n",
       "  14,\n",
       "  413,\n",
       "  414,\n",
       "  18,\n",
       "  87,\n",
       "  5,\n",
       "  415,\n",
       "  149,\n",
       "  2,\n",
       "  4,\n",
       "  70,\n",
       "  8,\n",
       "  40,\n",
       "  69,\n",
       "  38,\n",
       "  416,\n",
       "  3,\n",
       "  70,\n",
       "  52,\n",
       "  91,\n",
       "  87,\n",
       "  7],\n",
       " [15,\n",
       "  62,\n",
       "  25,\n",
       "  1,\n",
       "  7,\n",
       "  137,\n",
       "  49,\n",
       "  417,\n",
       "  65,\n",
       "  61,\n",
       "  129,\n",
       "  79,\n",
       "  418,\n",
       "  419,\n",
       "  420,\n",
       "  421,\n",
       "  422,\n",
       "  423,\n",
       "  424,\n",
       "  154,\n",
       "  68,\n",
       "  153,\n",
       "  30,\n",
       "  93,\n",
       "  30,\n",
       "  133,\n",
       "  124,\n",
       "  425],\n",
       " [21,\n",
       "  12,\n",
       "  13,\n",
       "  4,\n",
       "  33,\n",
       "  47,\n",
       "  66,\n",
       "  32,\n",
       "  4,\n",
       "  4,\n",
       "  426,\n",
       "  427,\n",
       "  155,\n",
       "  428,\n",
       "  429,\n",
       "  19,\n",
       "  146,\n",
       "  64,\n",
       "  155,\n",
       "  6,\n",
       "  20,\n",
       "  34,\n",
       "  96,\n",
       "  3,\n",
       "  63,\n",
       "  6,\n",
       "  5,\n",
       "  3,\n",
       "  53,\n",
       "  2,\n",
       "  3,\n",
       "  430,\n",
       "  14,\n",
       "  2,\n",
       "  55,\n",
       "  37,\n",
       "  130,\n",
       "  48,\n",
       "  36],\n",
       " [431,\n",
       "  12,\n",
       "  13,\n",
       "  4,\n",
       "  1,\n",
       "  7,\n",
       "  11,\n",
       "  1,\n",
       "  7,\n",
       "  72,\n",
       "  29,\n",
       "  432,\n",
       "  433,\n",
       "  15,\n",
       "  434,\n",
       "  435,\n",
       "  436,\n",
       "  437,\n",
       "  438,\n",
       "  439,\n",
       "  1,\n",
       "  7,\n",
       "  34,\n",
       "  29,\n",
       "  40,\n",
       "  440,\n",
       "  9,\n",
       "  2,\n",
       "  441,\n",
       "  72,\n",
       "  442,\n",
       "  4]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_train = tok.texts_to_sequences(x_train)\n",
    "seq_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  99, 100, 101],\n",
       "       [  0,   0,   0, ..., 196, 197, 198],\n",
       "       [  0,   0,   0, ...,  34,  35, 202],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 133, 124, 425],\n",
       "       [  0,   0,   0, ..., 130,  48,  36],\n",
       "       [  0,   0,   0, ...,  72, 442,   4]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_padded_train = sequence.pad_sequences(seq_train, maxlen=max_len)#convert word to number in array and add zero maintain sequence\n",
    "seq_padded_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# vectorization\n",
    "model.add(Embedding(vocab_len+1,80, input_length=max_len, mask_zero=True))\n",
    "# RNN layer\n",
    "model.add(SimpleRNN(32, activation=\"tanh\"))\n",
    "# ANN's hidden layer\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "# To check on overfitting\n",
    "model.add(Dropout(0.2))\n",
    "# output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 80, 80)            35440     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                3616      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 40,145\n",
      "Trainable params: 40,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6782\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5954\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5302\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5058\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4536\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4051\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3816\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3391\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3230\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3028\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2674\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2424\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2434\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1927\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1904\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1658\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1487\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1524\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1271\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1215\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1211\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1227\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0790\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0681\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0819\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0652\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0510\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0347\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0433\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0441\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0416\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0341\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0364\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0231\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0301\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0256\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0243\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0201\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0234\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0201\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0151\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0141\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0108\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0109\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0099\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0103\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0117\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0115\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15ff70f5b80>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(seq_padded_train, y_train, batch_size=50, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[369,\n",
       "  44,\n",
       "  79,\n",
       "  63,\n",
       "  150,\n",
       "  124,\n",
       "  8,\n",
       "  57,\n",
       "  338,\n",
       "  24,\n",
       "  8,\n",
       "  76,\n",
       "  254,\n",
       "  122,\n",
       "  6,\n",
       "  63,\n",
       "  6,\n",
       "  5,\n",
       "  93,\n",
       "  82,\n",
       "  195,\n",
       "  75,\n",
       "  17,\n",
       "  6,\n",
       "  10,\n",
       "  43,\n",
       "  124,\n",
       "  47],\n",
       " [1,\n",
       "  390,\n",
       "  10,\n",
       "  41,\n",
       "  125,\n",
       "  369,\n",
       "  246,\n",
       "  3,\n",
       "  85,\n",
       "  227,\n",
       "  300,\n",
       "  221,\n",
       "  17,\n",
       "  421,\n",
       "  3,\n",
       "  300,\n",
       "  17,\n",
       "  17,\n",
       "  75,\n",
       "  28,\n",
       "  8,\n",
       "  11,\n",
       "  1],\n",
       " [50,\n",
       "  30,\n",
       "  30,\n",
       "  128,\n",
       "  30,\n",
       "  6,\n",
       "  1,\n",
       "  5,\n",
       "  93,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  36,\n",
       "  50,\n",
       "  30,\n",
       "  30,\n",
       "  128,\n",
       "  30,\n",
       "  6,\n",
       "  1,\n",
       "  5,\n",
       "  93,\n",
       "  30,\n",
       "  30,\n",
       "  30,\n",
       "  36],\n",
       " [1,\n",
       "  10,\n",
       "  65,\n",
       "  7,\n",
       "  4,\n",
       "  1,\n",
       "  225,\n",
       "  226,\n",
       "  21,\n",
       "  22,\n",
       "  227,\n",
       "  26,\n",
       "  228,\n",
       "  229,\n",
       "  230,\n",
       "  26,\n",
       "  60,\n",
       "  52,\n",
       "  15,\n",
       "  31,\n",
       "  300,\n",
       "  301,\n",
       "  30,\n",
       "  74,\n",
       "  17,\n",
       "  220,\n",
       "  17,\n",
       "  17,\n",
       "  30,\n",
       "  5,\n",
       "  9,\n",
       "  92,\n",
       "  15,\n",
       "  31,\n",
       "  300,\n",
       "  30,\n",
       "  93,\n",
       "  30,\n",
       "  5,\n",
       "  3,\n",
       "  300,\n",
       "  17,\n",
       "  3,\n",
       "  195,\n",
       "  163,\n",
       "  313,\n",
       "  93,\n",
       "  30,\n",
       "  16,\n",
       "  35,\n",
       "  299,\n",
       "  27,\n",
       "  46,\n",
       "  145,\n",
       "  15,\n",
       "  132,\n",
       "  1],\n",
       " [6,\n",
       "  5,\n",
       "  5,\n",
       "  115,\n",
       "  92,\n",
       "  319,\n",
       "  12,\n",
       "  13,\n",
       "  320,\n",
       "  4,\n",
       "  7,\n",
       "  11,\n",
       "  321,\n",
       "  322,\n",
       "  323,\n",
       "  3,\n",
       "  324,\n",
       "  325,\n",
       "  16,\n",
       "  101,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  329,\n",
       "  123,\n",
       "  142,\n",
       "  330,\n",
       "  331,\n",
       "  332,\n",
       "  33,\n",
       "  85,\n",
       "  333],\n",
       " [23,\n",
       "  24,\n",
       "  258,\n",
       "  47,\n",
       "  22,\n",
       "  83,\n",
       "  126,\n",
       "  259,\n",
       "  57,\n",
       "  260,\n",
       "  9,\n",
       "  261,\n",
       "  127,\n",
       "  20,\n",
       "  128,\n",
       "  262,\n",
       "  263,\n",
       "  27,\n",
       "  9,\n",
       "  10,\n",
       "  84,\n",
       "  8,\n",
       "  264,\n",
       "  78,\n",
       "  26,\n",
       "  265,\n",
       "  20,\n",
       "  129,\n",
       "  41,\n",
       "  60,\n",
       "  130,\n",
       "  22,\n",
       "  266,\n",
       "  95,\n",
       "  8,\n",
       "  126,\n",
       "  267,\n",
       "  268,\n",
       "  106,\n",
       "  128,\n",
       "  269,\n",
       "  58,\n",
       "  270,\n",
       "  19,\n",
       "  131,\n",
       "  271,\n",
       "  272,\n",
       "  15,\n",
       "  132,\n",
       "  58,\n",
       "  273,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  31,\n",
       "  279,\n",
       "  280,\n",
       "  117,\n",
       "  24,\n",
       "  281,\n",
       "  104,\n",
       "  105,\n",
       "  44,\n",
       "  78,\n",
       "  24,\n",
       "  33,\n",
       "  85,\n",
       "  282,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  51,\n",
       "  133,\n",
       "  286,\n",
       "  24,\n",
       "  26,\n",
       "  287,\n",
       "  288],\n",
       " [309,\n",
       "  54,\n",
       "  20,\n",
       "  15,\n",
       "  25,\n",
       "  24,\n",
       "  421,\n",
       "  59,\n",
       "  124,\n",
       "  18,\n",
       "  145,\n",
       "  48,\n",
       "  91,\n",
       "  9,\n",
       "  4,\n",
       "  47,\n",
       "  399,\n",
       "  5,\n",
       "  28,\n",
       "  68,\n",
       "  75,\n",
       "  17,\n",
       "  220,\n",
       "  17,\n",
       "  74,\n",
       "  17],\n",
       " [23,\n",
       "  1,\n",
       "  213,\n",
       "  21,\n",
       "  4,\n",
       "  76,\n",
       "  109,\n",
       "  49,\n",
       "  134,\n",
       "  291,\n",
       "  47,\n",
       "  71,\n",
       "  135,\n",
       "  2,\n",
       "  57,\n",
       "  14,\n",
       "  2,\n",
       "  379,\n",
       "  380,\n",
       "  39,\n",
       "  18,\n",
       "  90,\n",
       "  48,\n",
       "  16,\n",
       "  64,\n",
       "  11,\n",
       "  381,\n",
       "  77,\n",
       "  9,\n",
       "  286,\n",
       "  74,\n",
       "  17,\n",
       "  10,\n",
       "  144,\n",
       "  6,\n",
       "  63,\n",
       "  6,\n",
       "  5,\n",
       "  40,\n",
       "  69,\n",
       "  38,\n",
       "  217,\n",
       "  28,\n",
       "  11,\n",
       "  46,\n",
       "  125],\n",
       " [21,\n",
       "  12,\n",
       "  13,\n",
       "  4,\n",
       "  33,\n",
       "  47,\n",
       "  66,\n",
       "  32,\n",
       "  4,\n",
       "  4,\n",
       "  426,\n",
       "  427,\n",
       "  155,\n",
       "  428,\n",
       "  429,\n",
       "  19,\n",
       "  146,\n",
       "  64,\n",
       "  155,\n",
       "  6,\n",
       "  20,\n",
       "  34,\n",
       "  96,\n",
       "  3,\n",
       "  63,\n",
       "  6,\n",
       "  5,\n",
       "  3,\n",
       "  53,\n",
       "  2,\n",
       "  3,\n",
       "  430,\n",
       "  14,\n",
       "  2,\n",
       "  55,\n",
       "  37,\n",
       "  130,\n",
       "  48,\n",
       "  36],\n",
       " [9,\n",
       "  7,\n",
       "  77,\n",
       "  72,\n",
       "  103,\n",
       "  4,\n",
       "  137,\n",
       "  72,\n",
       "  27,\n",
       "  34,\n",
       "  69,\n",
       "  38,\n",
       "  416,\n",
       "  90,\n",
       "  5,\n",
       "  3,\n",
       "  27,\n",
       "  28,\n",
       "  55,\n",
       "  341,\n",
       "  163,\n",
       "  110,\n",
       "  27,\n",
       "  28,\n",
       "  390,\n",
       "  268,\n",
       "  35,\n",
       "  393,\n",
       "  20,\n",
       "  60,\n",
       "  3,\n",
       "  54,\n",
       "  163,\n",
       "  144,\n",
       "  381,\n",
       "  217,\n",
       "  28,\n",
       "  11,\n",
       "  46,\n",
       "  125],\n",
       " [1,\n",
       "  263,\n",
       "  7,\n",
       "  76,\n",
       "  4,\n",
       "  11,\n",
       "  1,\n",
       "  263,\n",
       "  7,\n",
       "  311,\n",
       "  18,\n",
       "  38,\n",
       "  79,\n",
       "  3,\n",
       "  416,\n",
       "  110,\n",
       "  110,\n",
       "  73,\n",
       "  9,\n",
       "  154,\n",
       "  101,\n",
       "  73,\n",
       "  116,\n",
       "  42,\n",
       "  73,\n",
       "  77,\n",
       "  2,\n",
       "  15,\n",
       "  62,\n",
       "  25,\n",
       "  1,\n",
       "  76,\n",
       "  4]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_test = tok.texts_to_sequences(x_test)\n",
    "seq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        369,  44,  79,  63, 150, 124,   8,  57, 338,  24,   8,  76, 254,\n",
       "        122,   6,  63,   6,   5,  93,  82, 195,  75,  17,   6,  10,  43,\n",
       "        124,  47],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   1, 390,  10,  41, 125, 369, 246,   3,\n",
       "         85, 227, 300, 221,  17, 421,   3, 300,  17,  17,  75,  28,   8,\n",
       "         11,   1],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  50,  30,  30, 128,  30,   6,   1,   5,  93,  30,  30,\n",
       "         30,  36,  50,  30,  30, 128,  30,   6,   1,   5,  93,  30,  30,\n",
       "         30,  36],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  10,  65,\n",
       "          7,   4,   1, 225, 226,  21,  22, 227,  26, 228, 229, 230,  26,\n",
       "         60,  52,  15,  31, 300, 301,  30,  74,  17, 220,  17,  17,  30,\n",
       "          5,   9,  92,  15,  31, 300,  30,  93,  30,   5,   3, 300,  17,\n",
       "          3, 195, 163, 313,  93,  30,  16,  35, 299,  27,  46, 145,  15,\n",
       "        132,   1],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   5,   5, 115,\n",
       "         92, 319,  12,  13, 320,   4,   7,  11, 321, 322, 323,   3, 324,\n",
       "        325,  16, 101, 326, 327, 328, 329, 123, 142, 330, 331, 332,  33,\n",
       "         85, 333],\n",
       "       [ 23,  24, 258,  47,  22,  83, 126, 259,  57, 260,   9, 261, 127,\n",
       "         20, 128, 262, 263,  27,   9,  10,  84,   8, 264,  78,  26, 265,\n",
       "         20, 129,  41,  60, 130,  22, 266,  95,   8, 126, 267, 268, 106,\n",
       "        128, 269,  58, 270,  19, 131, 271, 272,  15, 132,  58, 273, 274,\n",
       "        275, 276, 277, 278,  31, 279, 280, 117,  24, 281, 104, 105,  44,\n",
       "         78,  24,  33,  85, 282, 283, 284, 285,  51, 133, 286,  24,  26,\n",
       "        287, 288],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 309,  54,  20,  15,  25,  24, 421,  59, 124,  18, 145,\n",
       "         48,  91,   9,   4,  47, 399,   5,  28,  68,  75,  17, 220,  17,\n",
       "         74,  17],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,  23,   1, 213,  21,   4,\n",
       "         76, 109,  49, 134, 291,  47,  71, 135,   2,  57,  14,   2, 379,\n",
       "        380,  39,  18,  90,  48,  16,  64,  11, 381,  77,   9, 286,  74,\n",
       "         17,  10, 144,   6,  63,   6,   5,  40,  69,  38, 217,  28,  11,\n",
       "         46, 125],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  21,  12,  13,   4,  33,  47,  66,  32,   4,   4, 426,\n",
       "        427, 155, 428, 429,  19, 146,  64, 155,   6,  20,  34,  96,   3,\n",
       "         63,   6,   5,   3,  53,   2,   3, 430,  14,   2,  55,  37, 130,\n",
       "         48,  36],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   9,   7,  77,  72, 103,   4, 137,  72,  27,  34,  69,  38,\n",
       "        416,  90,   5,   3,  27,  28,  55, 341, 163, 110,  27,  28, 390,\n",
       "        268,  35, 393,  20,  60,   3,  54, 163, 144, 381, 217,  28,  11,\n",
       "         46, 125],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   1, 263,   7,  76,   4,\n",
       "         11,   1, 263,   7, 311,  18,  38,  79,   3, 416, 110, 110,  73,\n",
       "          9, 154, 101,  73, 116,  42,  73,  77,   2,  15,  62,  25,   1,\n",
       "         76,   4]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_padded_test = sequence.pad_sequences(seq_test, maxlen=max_len)\n",
    "seq_padded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(seq_padded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat contains probability\n",
    "y_hat = np.where(y_hat>=0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report( y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6901\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6811\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6723\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6654\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6558\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6483\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6352\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6208\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6106\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5961\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5811\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5505\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5305\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5082\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4712\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4412\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4102\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3711\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3170\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2531\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2216\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1530\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1106\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0719\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0605\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0345\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0311\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0196\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0191\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0124\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0070\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0073\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0048\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0075\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0065\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0047\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0024\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0071\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0018\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0015\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0020\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0046\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0014\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.2938e-04\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f828cb880>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# vectorization\n",
    "model.add(Embedding(vocab_len+1,80, input_length=max_len, mask_zero=True))\n",
    "# RNN layer\n",
    "# model.add(SimpleRNN(32, activation=\"tanh\"))\n",
    "model.add(LSTM(32, activation=\"tanh\"))\n",
    "# ANN's hidden layer\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "# To check on overfitting\n",
    "model.add(Dropout(0.2))\n",
    "# output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "model.fit(seq_padded_train, y_train, batch_size=50, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(seq_padded_test)\n",
    "y_hat = np.where(y_hat>=0.5, 1, 0)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6949\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6872\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6823\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6746\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6688\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6617\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6511\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6402\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6326\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6210\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6123\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5996\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5763\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5620\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5583\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5364\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5206\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5007\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4614\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4523\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4317\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4088\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3702\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3476\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3149\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2873\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2698\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2200\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2082\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1549\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1330\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0833\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0584\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0601\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0456\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0273\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0141\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0112\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0056\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0051\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0024\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0027\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0040\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0029\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0018\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.7802e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f8b204ca0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# vectorization\n",
    "model.add(Embedding(vocab_len+1,80, input_length=max_len, mask_zero=True))\n",
    "# GRU layer\n",
    "model.add(GRU(32, activation=\"tanh\"))\n",
    "# ANN's hidden layer\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "# To check on overfitting|\n",
    "model.add(Dropout(0.2))\n",
    "# output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "model.fit(seq_padded_train, y_train, batch_size=50, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(seq_padded_test)\n",
    "y_hat = np.where(y_hat>=0.5, 1, 0)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
