{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTJQV4-OiOyz"
   },
   "source": [
    "Perform tokenization, stemming and lemmatization, stopwords and punctuation removal on the given text -\n",
    "\n",
    "\n",
    "\n",
    "\"A major drawback of statistical methods is that they require elaborate feature engineering. Since the early 2010s,[16] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning. Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (SMT).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w_LOL2qQiCyQ"
   },
   "outputs": [],
   "source": [
    "#  Tokenization\n",
    "doc=\"\"\"A major drawback of statistical methods is that they require elaborate feature engineering. \n",
    "Since the early 2010s,[16] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning. \n",
    "Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task \n",
    "(e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing).\n",
    " In some areas, this shift has entailed substantial changes in how NLP systems are designed, \n",
    " such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. \n",
    " For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to\n",
    "  machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment \n",
    "  and language modeling that was used in statistical machine translation (SMT)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5D37gb2iuYV",
    "outputId": "33576ee2-5e81-43ae-9144-f23e137f8e88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'major',\n",
       " 'drawback',\n",
       " 'of',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'is',\n",
       " 'that',\n",
       " 'they',\n",
       " 'require',\n",
       " 'elaborate',\n",
       " 'feature',\n",
       " 'engineering.',\n",
       " 'Since',\n",
       " 'the',\n",
       " 'early',\n",
       " '2010s,[16]',\n",
       " 'the',\n",
       " 'field',\n",
       " 'has',\n",
       " 'thus',\n",
       " 'largely',\n",
       " 'abandoned',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'shifted',\n",
       " 'to',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'for',\n",
       " 'machine',\n",
       " 'learning.',\n",
       " 'Popular',\n",
       " 'techniques',\n",
       " 'include',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'word',\n",
       " 'embeddings',\n",
       " 'to',\n",
       " 'capture',\n",
       " 'semantic',\n",
       " 'properties',\n",
       " 'of',\n",
       " 'words,',\n",
       " 'and',\n",
       " 'an',\n",
       " 'increase',\n",
       " 'in',\n",
       " 'end-to-end',\n",
       " 'learning',\n",
       " 'of',\n",
       " 'a',\n",
       " 'higher-level',\n",
       " 'task',\n",
       " '(e.g.,',\n",
       " 'question',\n",
       " 'answering)',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'relying',\n",
       " 'on',\n",
       " 'a',\n",
       " 'pipeline',\n",
       " 'of',\n",
       " 'separate',\n",
       " 'intermediate',\n",
       " 'tasks',\n",
       " '(e.g.,',\n",
       " 'part-of-speech',\n",
       " 'tagging',\n",
       " 'and',\n",
       " 'dependency',\n",
       " 'parsing).',\n",
       " 'In',\n",
       " 'some',\n",
       " 'areas,',\n",
       " 'this',\n",
       " 'shift',\n",
       " 'has',\n",
       " 'entailed',\n",
       " 'substantial',\n",
       " 'changes',\n",
       " 'in',\n",
       " 'how',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " 'are',\n",
       " 'designed,',\n",
       " 'such',\n",
       " 'that',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network-based',\n",
       " 'approaches',\n",
       " 'may',\n",
       " 'be',\n",
       " 'viewed',\n",
       " 'as',\n",
       " 'a',\n",
       " 'new',\n",
       " 'paradigm',\n",
       " 'distinct',\n",
       " 'from',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing.',\n",
       " 'For',\n",
       " 'instance,',\n",
       " 'the',\n",
       " 'term',\n",
       " 'neural',\n",
       " 'machine',\n",
       " 'translation',\n",
       " '(NMT)',\n",
       " 'emphasizes',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'deep',\n",
       " 'learning-based',\n",
       " 'approaches',\n",
       " 'to',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'directly',\n",
       " 'learn',\n",
       " 'sequence-to-sequence',\n",
       " 'transformations,',\n",
       " 'obviating',\n",
       " 'the',\n",
       " 'need',\n",
       " 'for',\n",
       " 'intermediate',\n",
       " 'steps',\n",
       " 'such',\n",
       " 'as',\n",
       " 'word',\n",
       " 'alignment',\n",
       " 'and',\n",
       " 'language',\n",
       " 'modeling',\n",
       " 'that',\n",
       " 'was',\n",
       " 'used',\n",
       " 'in',\n",
       " 'statistical',\n",
       " 'machine',\n",
       " 'translation',\n",
       " '(SMT)']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fgNT_62iyWF",
    "outputId": "c86fe62c-444e-438e-9a16-cc3f8f284ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt') #for word tokenization\n",
    "nltk.download('stopwords') #for removing or getting list of stopwords\n",
    "nltk.download('wordnet') #for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dQc39-Kfi6So"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r4X-ahj8i81o"
   },
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "tokens = word_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD0nHayYi_kx",
    "outputId": "e7c7a216-f7bd-464a-f821-ce92ada6ce01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'major',\n",
       " 'drawback',\n",
       " 'of',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'is',\n",
       " 'that',\n",
       " 'they',\n",
       " 'require',\n",
       " 'elaborate',\n",
       " 'feature',\n",
       " 'engineering',\n",
       " '.',\n",
       " 'Since',\n",
       " 'the',\n",
       " 'early',\n",
       " '2010s',\n",
       " ',',\n",
       " '[',\n",
       " '16',\n",
       " ']',\n",
       " 'the',\n",
       " 'field',\n",
       " 'has',\n",
       " 'thus',\n",
       " 'largely',\n",
       " 'abandoned',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'shifted',\n",
       " 'to',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'for',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'Popular',\n",
       " 'techniques',\n",
       " 'include',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'word',\n",
       " 'embeddings',\n",
       " 'to',\n",
       " 'capture',\n",
       " 'semantic',\n",
       " 'properties',\n",
       " 'of',\n",
       " 'words',\n",
       " ',',\n",
       " 'and',\n",
       " 'an',\n",
       " 'increase',\n",
       " 'in',\n",
       " 'end-to-end',\n",
       " 'learning',\n",
       " 'of',\n",
       " 'a',\n",
       " 'higher-level',\n",
       " 'task',\n",
       " '(',\n",
       " 'e.g.',\n",
       " ',',\n",
       " 'question',\n",
       " 'answering',\n",
       " ')',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'relying',\n",
       " 'on',\n",
       " 'a',\n",
       " 'pipeline',\n",
       " 'of',\n",
       " 'separate',\n",
       " 'intermediate',\n",
       " 'tasks',\n",
       " '(',\n",
       " 'e.g.',\n",
       " ',',\n",
       " 'part-of-speech',\n",
       " 'tagging',\n",
       " 'and',\n",
       " 'dependency',\n",
       " 'parsing',\n",
       " ')',\n",
       " '.',\n",
       " 'In',\n",
       " 'some',\n",
       " 'areas',\n",
       " ',',\n",
       " 'this',\n",
       " 'shift',\n",
       " 'has',\n",
       " 'entailed',\n",
       " 'substantial',\n",
       " 'changes',\n",
       " 'in',\n",
       " 'how',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " 'are',\n",
       " 'designed',\n",
       " ',',\n",
       " 'such',\n",
       " 'that',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network-based',\n",
       " 'approaches',\n",
       " 'may',\n",
       " 'be',\n",
       " 'viewed',\n",
       " 'as',\n",
       " 'a',\n",
       " 'new',\n",
       " 'paradigm',\n",
       " 'distinct',\n",
       " 'from',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.',\n",
       " 'For',\n",
       " 'instance',\n",
       " ',',\n",
       " 'the',\n",
       " 'term',\n",
       " 'neural',\n",
       " 'machine',\n",
       " 'translation',\n",
       " '(',\n",
       " 'NMT',\n",
       " ')',\n",
       " 'emphasizes',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'deep',\n",
       " 'learning-based',\n",
       " 'approaches',\n",
       " 'to',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'directly',\n",
       " 'learn',\n",
       " 'sequence-to-sequence',\n",
       " 'transformations',\n",
       " ',',\n",
       " 'obviating',\n",
       " 'the',\n",
       " 'need',\n",
       " 'for',\n",
       " 'intermediate',\n",
       " 'steps',\n",
       " 'such',\n",
       " 'as',\n",
       " 'word',\n",
       " 'alignment',\n",
       " 'and',\n",
       " 'language',\n",
       " 'modeling',\n",
       " 'that',\n",
       " 'was',\n",
       " 'used',\n",
       " 'in',\n",
       " 'statistical',\n",
       " 'machine',\n",
       " 'translation',\n",
       " '(',\n",
       " 'SMT',\n",
       " ')']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tJ29cd05jBZE"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dErI5qPkjJZn"
   },
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ErQyA3KWjK77"
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-T3WTVSOjMWX"
   },
   "outputs": [],
   "source": [
    "punc = list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVrCgTKYjN35",
    "outputId": "e13ff918-1003-4c6c-fb99-9643fb8f8d0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7A7X6JcjQgu",
    "outputId": "5ef46f0b-bc8f-4ee2-9c3c-12a568d9b457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QNt22CjwjYOa"
   },
   "outputs": [],
   "source": [
    "bad_tokens = stop + punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vKIsqcB6jb5V"
   },
   "outputs": [],
   "source": [
    "clean_tokens = []\n",
    "for t in tokens:\n",
    "  if t not in bad_tokens:\n",
    "    clean_tokens.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE-yoXG0jfiP",
    "outputId": "ff706079-2df8-4ad8-9144-26bc11219cdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'major',\n",
       " 'drawback',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'require',\n",
       " 'elaborate',\n",
       " 'feature',\n",
       " 'engineering',\n",
       " 'Since',\n",
       " 'early',\n",
       " '2010s',\n",
       " '16',\n",
       " 'field',\n",
       " 'thus',\n",
       " 'largely',\n",
       " 'abandoned',\n",
       " 'statistical',\n",
       " 'methods',\n",
       " 'shifted',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'Popular',\n",
       " 'techniques',\n",
       " 'include',\n",
       " 'use',\n",
       " 'word',\n",
       " 'embeddings',\n",
       " 'capture',\n",
       " 'semantic',\n",
       " 'properties',\n",
       " 'words',\n",
       " 'increase',\n",
       " 'end-to-end',\n",
       " 'learning',\n",
       " 'higher-level',\n",
       " 'task',\n",
       " 'e.g.',\n",
       " 'question',\n",
       " 'answering',\n",
       " 'instead',\n",
       " 'relying',\n",
       " 'pipeline',\n",
       " 'separate',\n",
       " 'intermediate',\n",
       " 'tasks',\n",
       " 'e.g.',\n",
       " 'part-of-speech',\n",
       " 'tagging',\n",
       " 'dependency',\n",
       " 'parsing',\n",
       " 'In',\n",
       " 'areas',\n",
       " 'shift',\n",
       " 'entailed',\n",
       " 'substantial',\n",
       " 'changes',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " 'designed',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network-based',\n",
       " 'approaches',\n",
       " 'may',\n",
       " 'viewed',\n",
       " 'new',\n",
       " 'paradigm',\n",
       " 'distinct',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'For',\n",
       " 'instance',\n",
       " 'term',\n",
       " 'neural',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'NMT',\n",
       " 'emphasizes',\n",
       " 'fact',\n",
       " 'deep',\n",
       " 'learning-based',\n",
       " 'approaches',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'directly',\n",
       " 'learn',\n",
       " 'sequence-to-sequence',\n",
       " 'transformations',\n",
       " 'obviating',\n",
       " 'need',\n",
       " 'intermediate',\n",
       " 'steps',\n",
       " 'word',\n",
       " 'alignment',\n",
       " 'language',\n",
       " 'modeling',\n",
       " 'used',\n",
       " 'statistical',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'SMT']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "68GXVhqFjnbT"
   },
   "outputs": [],
   "source": [
    "clean_tokens = [t for t in tokens if t not in bad_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNreG6f3jq59",
    "outputId": "a8929ef7-c806-485a-b89b-011e603537cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HPY43xHjw54",
    "outputId": "5939d810-1c9f-479d-b2b5-5b9aa22a0466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Oxrbnn5Ijy7s"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9B8nz5b-j5Gq",
    "outputId": "e9f4217e-9eed-4e05-b323-f21902edcbbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "major\n",
      "drawback\n",
      "statist\n",
      "method\n",
      "requir\n",
      "elabor\n",
      "featur\n",
      "engin\n",
      "sinc\n",
      "earli\n",
      "2010\n",
      "16\n",
      "field\n",
      "thu\n",
      "larg\n",
      "abandon\n",
      "statist\n",
      "method\n",
      "shift\n",
      "neural\n",
      "network\n",
      "machin\n",
      "learn\n",
      "popular\n",
      "techniqu\n",
      "includ\n",
      "use\n",
      "word\n",
      "embed\n",
      "captur\n",
      "semant\n",
      "properti\n",
      "word\n",
      "increas\n",
      "end-to-end\n",
      "learn\n",
      "higher-level\n",
      "task\n",
      "e.g.\n",
      "question\n",
      "answer\n",
      "instead\n",
      "reli\n",
      "pipelin\n",
      "separ\n",
      "intermedi\n",
      "task\n",
      "e.g.\n",
      "part-of-speech\n",
      "tag\n",
      "depend\n",
      "pars\n",
      "In\n",
      "area\n",
      "shift\n",
      "entail\n",
      "substanti\n",
      "chang\n",
      "nlp\n",
      "system\n",
      "design\n",
      "deep\n",
      "neural\n",
      "network-bas\n",
      "approach\n",
      "may\n",
      "view\n",
      "new\n",
      "paradigm\n",
      "distinct\n",
      "statist\n",
      "natur\n",
      "languag\n",
      "process\n",
      "for\n",
      "instanc\n",
      "term\n",
      "neural\n",
      "machin\n",
      "translat\n",
      "nmt\n",
      "emphas\n",
      "fact\n",
      "deep\n",
      "learning-bas\n",
      "approach\n",
      "machin\n",
      "translat\n",
      "directli\n",
      "learn\n",
      "sequence-to-sequ\n",
      "transform\n",
      "obviat\n",
      "need\n",
      "intermedi\n",
      "step\n",
      "word\n",
      "align\n",
      "languag\n",
      "model\n",
      "use\n",
      "statist\n",
      "machin\n",
      "translat\n",
      "smt\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "for c in clean_tokens:\n",
    "  print(porter.stem(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtnCvA33krDl",
    "outputId": "a17cabf1-b269-4be8-df5d-b15c22d03c78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'maj',\n",
       " 'drawback',\n",
       " 'stat',\n",
       " 'method',\n",
       " 'requir',\n",
       " 'elab',\n",
       " 'feat',\n",
       " 'engin',\n",
       " 'sint',\n",
       " 'ear',\n",
       " '2010s',\n",
       " '16',\n",
       " 'field',\n",
       " 'thu',\n",
       " 'larg',\n",
       " 'abandon',\n",
       " 'stat',\n",
       " 'method',\n",
       " 'shift',\n",
       " 'neur',\n",
       " 'network',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'popul',\n",
       " 'techn',\n",
       " 'includ',\n",
       " 'us',\n",
       " 'word',\n",
       " 'embed',\n",
       " 'capt',\n",
       " 'sem',\n",
       " 'property',\n",
       " 'word',\n",
       " 'increas',\n",
       " 'end-to-end',\n",
       " 'learn',\n",
       " 'higher-level',\n",
       " 'task',\n",
       " 'e.g.',\n",
       " 'quest',\n",
       " 'answ',\n",
       " 'instead',\n",
       " 'rely',\n",
       " 'pipelin',\n",
       " 'sep',\n",
       " 'intermedy',\n",
       " 'task',\n",
       " 'e.g.',\n",
       " 'part-of-speech',\n",
       " 'tag',\n",
       " 'depend',\n",
       " 'pars',\n",
       " 'in',\n",
       " 'area',\n",
       " 'shift',\n",
       " 'entail',\n",
       " 'subst',\n",
       " 'chang',\n",
       " 'nlp',\n",
       " 'system',\n",
       " 'design',\n",
       " 'deep',\n",
       " 'neur',\n",
       " 'network-based',\n",
       " 'approach',\n",
       " 'may',\n",
       " 'view',\n",
       " 'new',\n",
       " 'paradigm',\n",
       " 'distinct',\n",
       " 'stat',\n",
       " 'nat',\n",
       " 'langu',\n",
       " 'process',\n",
       " 'for',\n",
       " 'inst',\n",
       " 'term',\n",
       " 'neur',\n",
       " 'machin',\n",
       " 'transl',\n",
       " 'nmt',\n",
       " 'emphas',\n",
       " 'fact',\n",
       " 'deep',\n",
       " 'learning-based',\n",
       " 'approach',\n",
       " 'machin',\n",
       " 'transl',\n",
       " 'direct',\n",
       " 'learn',\n",
       " 'sequence-to-sequenc',\n",
       " 'transform',\n",
       " 'obvy',\n",
       " 'nee',\n",
       " 'intermedy',\n",
       " 'step',\n",
       " 'word',\n",
       " 'align',\n",
       " 'langu',\n",
       " 'model',\n",
       " 'us',\n",
       " 'stat',\n",
       " 'machin',\n",
       " 'transl',\n",
       " 'smt']"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster = LancasterStemmer()\n",
    "[lancaster.stem(c) for c in clean_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "536L-tOOk1PK"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2N8o1eGOk5Uw",
    "outputId": "5f27dd2f-9fcf-4c67-eb50-066106d0c92b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'major',\n",
       " 'drawback',\n",
       " 'statistical',\n",
       " 'method',\n",
       " 'require',\n",
       " 'elaborate',\n",
       " 'feature',\n",
       " 'engineering',\n",
       " 'Since',\n",
       " 'early',\n",
       " '2010s',\n",
       " '16',\n",
       " 'field',\n",
       " 'thus',\n",
       " 'largely',\n",
       " 'abandoned',\n",
       " 'statistical',\n",
       " 'method',\n",
       " 'shifted',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'Popular',\n",
       " 'technique',\n",
       " 'include',\n",
       " 'use',\n",
       " 'word',\n",
       " 'embeddings',\n",
       " 'capture',\n",
       " 'semantic',\n",
       " 'property',\n",
       " 'word',\n",
       " 'increase',\n",
       " 'end-to-end',\n",
       " 'learning',\n",
       " 'higher-level',\n",
       " 'task',\n",
       " 'e.g.',\n",
       " 'question',\n",
       " 'answering',\n",
       " 'instead',\n",
       " 'relying',\n",
       " 'pipeline',\n",
       " 'separate',\n",
       " 'intermediate',\n",
       " 'task',\n",
       " 'e.g.',\n",
       " 'part-of-speech',\n",
       " 'tagging',\n",
       " 'dependency',\n",
       " 'parsing',\n",
       " 'In',\n",
       " 'area',\n",
       " 'shift',\n",
       " 'entailed',\n",
       " 'substantial',\n",
       " 'change',\n",
       " 'NLP',\n",
       " 'system',\n",
       " 'designed',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network-based',\n",
       " 'approach',\n",
       " 'may',\n",
       " 'viewed',\n",
       " 'new',\n",
       " 'paradigm',\n",
       " 'distinct',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'For',\n",
       " 'instance',\n",
       " 'term',\n",
       " 'neural',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'NMT',\n",
       " 'emphasizes',\n",
       " 'fact',\n",
       " 'deep',\n",
       " 'learning-based',\n",
       " 'approach',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'directly',\n",
       " 'learn',\n",
       " 'sequence-to-sequence',\n",
       " 'transformation',\n",
       " 'obviating',\n",
       " 'need',\n",
       " 'intermediate',\n",
       " 'step',\n",
       " 'word',\n",
       " 'alignment',\n",
       " 'language',\n",
       " 'modeling',\n",
       " 'used',\n",
       " 'statistical',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'SMT']"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "[lemma.lemmatize(c) for c in clean_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbLCCfJrk-hV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "tokenization_stemming .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
